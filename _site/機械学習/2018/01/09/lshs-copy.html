<!DOCTYPE html>
<html>    
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width initial-scale=1">

  <title>Leaf-Smoothed Hierarchical Softmax for Ordinal Prediction</title>
  <meta name="description" content="元論文: http://www.cs.utexas.edu/~tansey/aaai18-lshs.pdf">
  <meta name="google-site-verification" content="jhcQ391AbIJxLfLGHuUvmNEmr1luyROr-4GbAYF4mNE" />
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@nocotan">
  <meta name="twitter:creator" content="@nocotan">
  
    <meta name="twitter:title" content="Leaf-Smoothed Hierarchical Softmax for Ordinal Prediction">
  
  
    <meta name="twitter:url" content="http://localhost:4000/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/2018/01/09/lshs-copy.html">
  
  
    <meta name="twitter:description" content="雑記
">
  
  <meta name="twitter:description" content="元論文: http://www.cs.utexas.edu/~tansey/aaai18-lshs.pdf

概要
階層的ソフトマックス(hSm: Hierarchical Softmax)の特殊系に関する研究．
hSmの一般的な代替モデルとしてLeaf-smoothed Hierarchical Softmax(LSHS)を提案．
LSHSは，最初にkd木に類似した方法で出力確率の階層的分...">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/nocotan/nocotan.github.io/master/images/icon.jpg">
  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/2018/01/09/lshs-copy.html">
  <link rel="alternate" type="application/atom+xml" title="nocohub" href="http://localhost:4000/feed.xml" />
  <script src="/scripts/jquery-1.11.2.min.js"></script>
  <script src="/scripts/pithy.js"></script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74313651-2', 'auto');
  ga('send', 'pageview');
  </script>
</head>


  <body>
    <header class="header">
	<div class="header-container">
		<div class="nav">
			
				<li>
					<a href="/index">home</a>
				</li>			
			
			
				<li>
					<a href="/archive">archive</a>
				</li>			
			
			
				<li>
					<a href="/category">category</a>
				</li>			
			
			
				<li>
					<a href="/about">about</a>
				</li>			
			
		</div>
		<div class="description">  </div>		
		<ul class="social-links">
			<li>
				<a href="https://github.com/nocotan" title="Github">
					<img width="19px" height="19px" src="/images/github.png"/>
				</a>
			</li>
			<li>
				<a href="/feed.xml" title="RSS">
					<img width="19px" height="19px" src="/images/rss.png"/>
				</a>
			</li>
			<li>
				<a href="https://twitter.com/machinery81" title="Twitter">
					<img width="19px" height="19px" src="/images/twitter.png"/>
				</a>
			</li>
		</ul>
	</div>
</header>

    <br>
    <div class="page-content">
      <div class="wrapper">
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$']]}
    });
</script>
<div class="post">
  <br>
  <header class="post-header">
    <h1 class="post-title">Leaf-Smoothed Hierarchical Softmax for Ordinal Prediction</h1>
    <p class="post-meta">Jan 9, 2018</p>
  </header>

  <article class="post-content">
    <p>元論文: <a href="http://www.cs.utexas.edu/~tansey/aaai18-lshs.pdf">http://www.cs.utexas.edu/~tansey/aaai18-lshs.pdf</a></p>

<h2 id="概要">概要</h2>
<p>階層的ソフトマックス(hSm: Hierarchical Softmax)の特殊系に関する研究．
hSmの一般的な代替モデルとしてLeaf-smoothed Hierarchical Softmax(LSHS)を提案．
LSHSは，最初にkd木に類似した方法で出力確率の階層的分解を用いて順序ラベル空間の構造を利用する．
これによってモデル全体のサンプル効率は向上するが，一部空間でのエラーが上昇してしまう，
これを克服するため，対象値の周辺領域を平滑化する正規化手法を導入する．</p>

<h2 id="貢献">貢献</h2>
<ul>
  <li>既存のCPEモデルの詳細な分析</li>
  <li>大規模なドメインに対するスケーラブルなグラフベースの正規化手法を提案</li>
  <li>深層学習モデルを用いた離散確率分布を推定するノンパラメトリックな手法であるLeaf-Smoothed Hierarchical Softmaxを提案．</li>
</ul>

<h2 id="hierarchical-softmax-variant">Hierarchical softmax variant</h2>
<p>提案手法では，kd木から着想を得た領域分割の手法を用いてhSmを効率化する．</p>

<div align="center">
<img src="/images/20180109/lshs_fig1.png" width="500px" />
</div>

<h3 id="dyadic-decomposition">Dyadic decomposition</h3>
<p>多項分布から直接確率を出力するのではなく，ルートノードが順序空間の中心となるような平衡二分木を生成する．</p>

<ul>
  <li>ルートノードから順序空間を再帰的に二分割していく</li>
  <li>サイズnの空間から得られる木はn-1個のノードをもつ</li>
  <li>Deep Learningモデルは独立した二値分類の結果列を出力する</li>
</ul>

<script type="math/tex; mode=display">p(y > b_i | x) = \frac{1}{1 + exp(- \epsilon_i)}</script>

<p>ここで，<script type="math/tex">b_i</script>は各ノードとなる．</p>

<p>このような構造を利用することで，計算量の効率化ができる．
これを用いることで，与えられた学習例に対する確率の推論において，ルートから<script type="math/tex">O(\log_{2} n)</script>のパスのみの計算ですむ．</p>

<h3 id="multiple-dimensions">Multiple dimensions</h3>
<p>提案手法では，hierarchical softmaxの手法を，平衡kd木に類似した方法を用いて多次元分布へ拡張する．
これは木の各レベルで次元を交互に変えながら，木の分割を幅優先的に列挙することで実現する．</p>

<h2 id="leaf-smoothing">Leaf smoothing</h2>
<p>上記の木構造を用いる場合，パーティションを跨いだ近傍ラベルとの間に局所的な偏りが生じてしまう．</p>

<p>Figure 1を例に説明する．
例えば，<script type="math/tex">y_i = 4</script>の場合，ノードAとCもリーフ5に向いているため，結果として<script type="math/tex">p(y_i = 5 | x_i)</script>の確率も増加する．
一方で<script type="math/tex">p(y_i = 3)</script>に関しては，ノードAがリーフ3とは逆をむくため，確率が下がることがわかる．
この更新時の不均衡は，基礎となる条件付き分布の推定におけるギザギザした誤差分布を引き起こす．</p>

<p>これに対処するため，特定のパスだけでなく，目標の近傍を考慮した平滑化を導入する．</p>

<div align="center">
<img src="/images/20180109/lshs_fig2.png" width="800px" />
</div>

<h3 id="trend-filtering-logits">Trend filtering logits</h3>
<p>観測点同士の依存関係をグラフ構造として表現する問題は，様々な分野で広く研究されているテーマである．
こうした問題に対するものの中に，ノイズを含む観測点からなる既知のグラフ構造から，隣接点同士の潜在的な関係を利用するものがある．
これによって，全ノード間についての関係を調べる必要がなくなるため，効率的である．</p>

<p>Trend filtering (TF)は，以下の凸最適化問題を解くために提案されたデノイジング技術である．</p>

<script type="math/tex; mode=display">minimize_{\beta \in \mathcal{R}^N} \ \ \ell (y, \beta) + \lambda || \Delta^{(k)} \beta ||_{1}</script>

<p><script type="math/tex">y</script>はノイズの多い観測ベクトルである．</p>

<p>提案手法では，ラベル空間からd次元格子グラフを導出することでTFを適用する．
上式を変形して得られる損失関数は以下のようになる．</p>

<script type="math/tex; mode=display">L_i = - \log [p(y = y_i|x_i)] + \lambda || \Delta^{(k)} vec (\log [p(y|x_i)]) ||_1</script>

<h3 id="local-smoothing-via-neighborhood-sampling">Local smoothing via neighborhood sampling</h3>
<p>TFによって全点間の平滑化を行うのは時間的計算量がかかってしまうため，目的値の近傍のみを平滑化する．
具体的には<script type="math/tex">y_i</script>が与えられた時，出力空間内で<script type="math/tex">y_i</script>の半径<script type="math/tex">r</script>のノードについて平滑化を行う．</p>

<script type="math/tex; mode=display">L_i = - log [p(u = y_i | x_i)] + \lambda || \tilde{\Delta{}}^{(k)} \ell (y_i, x_i) ||_1</script>

<h3 id="実験結果">実験結果</h3>

<div align="center">
<img src="/images/20180109/lshs_fig3.png" width="800px" />
</div>

<h2 id="参考文献">参考文献</h2>
<p>Tansey, Wesley, Karl Pichotta, and James G. Scott. “Leaf-Smoothed Hierarchical Softmax for Ordinal Prediction.” (2018).</p>

  </article>
</div>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <br><br>
        <a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="vertical-normal" data-hatena-bookmark-lang="ja" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
        <a href="https://twitter.com/share" class="twitter-share-button" data-via="machinery81">Tweet</a><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
      </div>
    </div>
    
    <footer class="footer">
  <div id="gotop">^</div>
  <br>
	@2015 Pithy Theme by Pawpaw.
</footer>

    
  </body>

</html>
