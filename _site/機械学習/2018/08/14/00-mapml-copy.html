<!DOCTYPE html>
<html>    
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width initial-scale=1">

  <title>Large-scale Metric Learning with Uncertainty</title>
  <meta name="description" content="paper link">
  <meta name="google-site-verification" content="jhcQ391AbIJxLfLGHuUvmNEmr1luyROr-4GbAYF4mNE" />
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@nocotan">
  <meta name="twitter:creator" content="@nocotan">
  
    <meta name="twitter:title" content="Large-scale Metric Learning with Uncertainty">
  
  
    <meta name="twitter:url" content="http://localhost:4000/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/2018/08/14/00-mapml-copy.html">
  
  
    <meta name="twitter:description" content="雑記
">
  
  <meta name="twitter:description" content="paper link


Abstract
既存のmetric learningの多くはpairwise制約もしくはtriplet制約に基づいているが，それらの制約は，ナイーブにはサンプル数に対して$O(N^2)$もしくは$O(N^3)$であるため，大規模データセットへの適用は現実的ではない．加えて，現実世界の画像のようなデータには様々な不確実性が含まれる可能性があり，それらは学習の失敗と性...">
  <meta name="twitter:image" content="https://raw.githubusercontent.com/nocotan/nocotan.github.io/master/images/icon.jpg">
  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/2018/08/14/00-mapml-copy.html">
  <link rel="alternate" type="application/atom+xml" title="nocohub" href="http://localhost:4000/feed.xml" />
  <script src="/scripts/jquery-1.11.2.min.js"></script>
  <script src="/scripts/pithy.js"></script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-74313651-2', 'auto');
  ga('send', 'pageview');
  </script>
</head>


  <body>
    <header class="header">
	<div class="header-container">
		<div class="nav">
			
				<li>
					<a href="/index">home</a>
				</li>			
			
			
				<li>
					<a href="/archive">archive</a>
				</li>			
			
			
				<li>
					<a href="/category">category</a>
				</li>			
			
			
				<li>
					<a href="/about">about</a>
				</li>			
			
		</div>
		<div class="description">  </div>		
		<ul class="social-links">
			<li>
				<a href="https://github.com/nocotan" title="Github">
					<img width="19px" height="19px" src="/images/github.png"/>
				</a>
			</li>
			<li>
				<a href="/feed.xml" title="RSS">
					<img width="19px" height="19px" src="/images/rss.png"/>
				</a>
			</li>
			<li>
				<a href="https://twitter.com/machinery81" title="Twitter">
					<img width="19px" height="19px" src="/images/twitter.png"/>
				</a>
			</li>
		</ul>
	</div>
</header>

    <br>
    <div class="page-content">
      <div class="wrapper">
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$']]}
    });
</script>
<div class="post">
  <br>
  <header class="post-header">
    <h1 class="post-title">Large-scale Metric Learning with Uncertainty</h1>
    <p class="post-meta">Aug 14, 2018</p>
  </header>

  <article class="post-content">
    <p><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Qian_Large-Scale_Distance_Metric_CVPR_2018_paper.pdf">paper link</a></p>

<p><img width="480" alt="スクリーンショット 2018-08-13 15.05.06.png (165.4 kB)" src="https://img.esa.io/uploads/production/attachments/9763/2018/08/13/40745/a4d95984-92d6-4fb1-9e65-22bdd7b78ab5.png" /></p>
<h1 id="abstract">Abstract</h1>
<p>既存のmetric learningの多くはpairwise制約もしくはtriplet制約に基づいているが，それらの制約は，ナイーブにはサンプル数に対して$O(N^2)$もしくは$O(N^3)$であるため，大規模データセットへの適用は現実的ではない．加えて，現実世界の画像のようなデータには様々な不確実性が含まれる可能性があり，それらは学習の失敗と性能の低下を誘発する．本研究では，latent examplesとdistance metricを同時に学習するmargin preserving metric learningのフレームワークを提案する．Latent examplesの理想的な特性を活用することで，学習効率の大幅な改善と，学習後に得られるmetricの不確実性に対する頑健性を達成する．</p>

<h1 id="貢献">貢献</h1>
<ul>
  <li>大規模データに適用可能なmetric learningの手法を提案</li>
  <li>image dataに対する観察から，オリジナルデータではなく潜在的な代表サンプルに対するmetric learningが有効であることを示す</li>
</ul>

<h1 id="手法の説明">手法の説明</h1>
<h2 id="margin-preserving-metric-learning">Margin Preserving Metric Learning</h2>
<ul>
  <li>学習データ集合: { $(x_i, y_i), i=1,\dots, n$ },　$x_i \in \mathbb{R}^d$</li>
</ul>

<p>DMLは以下のような距離指標を学習したい:
<script type="math/tex">\forall{x_i, x_j, x_k} \ \ \ D^2(x_i, x_k) - D^2(x_i, x_j) \geq 1</script>
ここで$x_i$と$x_j$は同じクラス，$x_k$は違うクラスとする．
距離指標$M\in S^{d\times{d}}_+$が与えられた時，二乗距離は次のように定義される:
<script type="math/tex">D^2_M(x_i, x_j) = (x_i - x_j)^T M(x_i - x_j)</script></p>

<p>大規模画像データ集合について，観測されたサンプルが潜在的な代表サンプルから0を平均とする歪みに基づいて得られていると仮定する．
<script type="math/tex">\forall{i} \ \ \ E[x_i] = z_{o: f(i) = o}</script>
$f(\cdot)$は元のデータを対応するlatent exampleに射影する．</p>

<p>目的関数は，
<script type="math/tex">\forall{x_i, x_j, x_k} \ \ \ E[D^2_M(x_i, x_k)] - E[D^2_M(x_i, x_j)] \geq 1</script>
となる．</p>

<p>$z_o$,$z_p$，$z_q$を$x_i$，$x_j$，$x_k$に対応するlatent examplesとすると，同じクラスのペアについての距離函数は，
<script type="math/tex">E[D^2_M(x_i, x_j)] = D^2_M(z_o, z_p) + 2E[D^2_M(x_i, z_o)]</script>
同様に，異なるクラスのペアについての距離函数は，
<script type="math/tex">E[D^2_M(x_i, x_k)] = D^2_M(z_o, z_q) + E[D^2_M(x_i, z_o)] + E[D^2_M(x_k, z_q)] \geq D^2_M(z_o, z_q) + E[D^2_M(x_i, z_o)]</script>
となる．
以上から，triplet constraints下で学習する距離指標は次のように定義できる．
<script type="math/tex">\forall{z_o, z_p, z_q} \ \ \ D^2_M(z_o, z_q) - D^2_M(z_o, z_p) \geq 1 + E[D^2_M(x_i, z_o)]</script>
上式の制約で得られる距離函数は，右辺から同じローカルクラスタの中の距離はタイトであり，左辺から，異なるクラス間は異なる距離マージンを獲得できることがわかる．</p>

<p>triplet集合{$z^t_o, z^t_p, z^t_q$}について，最適化問題は以下のように定式化できる．
<script type="math/tex">\min_{M\in{S^{d\times{d}}_+}, ||M||_F\leq{\delta, z\in{\mathbb{R}^{d\times{m}}}}} L(M, z) = \sum_t l(z^t_o, z^t_p, z^t_q; M)</script>
$m\ll n$はlatent examplesの数．過学習を抑制するためFrobeniusノルムを追加し，損失関数にはヒンジロスを採用する．
<script type="math/tex">l(z^t_o, z^t_p, z^t_q; M) = [1 + E[D^2_M(x^t_i, z^t_o)] - (D^2_M(z^t_o, z^t_q) - D^2_M(z^t_o, z^t_p))] _+</script>
この問題は，距離指標とlatent examplesの両方が変数であるため最適化が難しいので，この論文ではこれを解く新しい手法を提案する．</p>

<h2 id="update-z-with-upper-bound">Update $z$ with Upper Bound</h2>
<p>$M_{k-1}$を固定した時，k番目のイテレーションについての部分問題は次のようになる．
<script type="math/tex">\min_z L(M_{k-1}, z) = \sum_t [1 + \underbrace{E[D^2_{M_{k-1}} (x^t_i, z^t_o)]}_ {a} - \underbrace{(D^2_{M_{k-1}} (z^t_o, z^t_q) - D^2_{M_{k-1}} (z^t_o, z^t_p))}_ {b}]_+</script></p>

<ul>
  <li>$a$: マージン項</li>
  <li>$b$: triplet差分項</li>
</ul>

<p>二つの項の両方に$z$が存在するため直接最適化するのは難しいので，元の問題のupper-boundを見つけて，代わりとなる単純な問題に落とす．</p>

<p>定数$c_1$，$c_2$および$c_3$について，以下の関数$F_r(z)$を考える．
<script type="math/tex">F_r(z) = c_1 E[D^2_{M_{k-1}} (x_i, z_o)] + c_2 + c_3 \sum_o D^2_{M_{k-1}}(z_o, z^{k-1}_o)</script>
ここで$\sum_r F_r(z^{k-1}) = L(M _{k-1}, z^{k-1})$．
定数項を消して並び替えると，関数$F_r(z)$の最適化は以下の関数$\tilde{F}_r(z)$の最適化に等しい．</p>

<script type="math/tex; mode=display">\min_{z\in{\mathbb{R}^{d\times{m_r}}}, \mu_i, o \in {0, 1}, \sum_o{\mu_{i, o}} = 1} \tilde{F}_r(z) = \sum_i \sum_o \mu _{i, o} D _{M _{k-1}}^2 (x_i, z_o) + \gamma \sum_o D _{M _{k-1}}^2(z_o, z^{k-1}_o)</script>

<p>元の目的関数$L(M_{k-1}, z)$の上界は$\sum_r F_r(z)$で与えられる．ここから，一般的なEMアルゴリズムを用いて上界の最小化ができる．
$\mu$を固定すると，latent examplesの近似解は以下で与えられる:</p>

<script type="math/tex; mode=display">\forall{o} z_o = \frac{1}{\sum_i \mu_{i, o} + \gamma}(\sum_i \mu_{i, o} x_i + \gamma z^{k-1}_o)</script>

<p>逆に$z$を固定すると，$\mu$は距離函数に基づいて，オリジナルデータを最も近傍のlatent exampleに割り当てる．</p>

<script type="math/tex; mode=display">% <![CDATA[
\forall{i} \mu_{i, o} = \begin{cases}
1 & o = argmin_o D_{M_{k-1}}^2 (x_i, z_o) \newline
0 & otherwise \newline
\end{cases} %]]></script>

<p>まとめるとAlg. 1にしめすアルゴリズムによって$z$の更新ができる．
<img width="440" alt="スクリーンショット 2018-08-13 15.07.02.png (66.9 kB)" src="https://img.esa.io/uploads/production/attachments/9763/2018/08/13/40745/8b574235-7d85-4699-9018-8964770bd15f.png" /></p>

<h2 id="update-m-with-upper-bound">Update $M$ with Upper Bound</h2>
<p>$z^k$を固定すると，k番目のイテレーションにおける部分問題は以下のようになる．</p>

<script type="math/tex; mode=display">\min_{M\in{S^{d\times{d}}_+}} = \sum_t [1 + E[D_M^2 (x^t_i, z^t_o)] - (D^2_M(z^t_o, z^t_q) - D^2_M(z^t_o, z^t_p))] _+</script>

<p>目的関数$L(M, z^k)$は以下に示す関数$H(M)$によって上界が求まる．
<script type="math/tex">H(M) = \frac{\lambda}{2} ||M - M_{k-1}||^2_F + \sum_t [1 + E[D^2_{M_{k-1}}(x^t_i, z^t_o)] - (D^2_M(z^t_o, z^t_q) - D^2_M(z^t_o, z^t_p))]_+</script></p>

<p>$\lambda$は定数で，$H(M_{k-1}) = L(M _{k-1}, z^k)$．
$H(M)$の最小化は一般的なDMLの問題．
潜在変数$z$の数はオリジナルデータに比べて少ないため，既存の最適化手法が良好に動作する(論文ではSGDを使用)．
Alg. 2に示すアルゴリズムで最適化を行う．</p>

<p><img width="440" alt="スクリーンショット 2018-08-13 15.19.06.png (103.6 kB)" src="https://img.esa.io/uploads/production/attachments/9763/2018/08/13/40745/f606da90-4bcf-4e80-8bd2-122edb6a3700.png" /></p>

<p>上記の二つのアルゴリズムを組み合わせて，全体を通した提案手法のアルゴリズムはAlg. 3に示される．</p>

<p><img width="440" alt="スクリーンショット 2018-08-13 15.20.26.png (65.2 kB)" src="https://img.esa.io/uploads/production/attachments/9763/2018/08/13/40745/6c11a6c5-b954-44ac-b4b6-5fd4e0c83ca6.png" /></p>

<h1 id="実験結果">実験結果</h1>

<p>比較手法は以下:</p>
<ul>
  <li>$Euclid$: 3近傍のユークリッド距離</li>
  <li>$LMNN$</li>
  <li>$OASIS$</li>
  <li>$HR-SGD$</li>
  <li>$MaPML_\tau$: 提案手法．潜在変数同士で3近傍をとる</li>
  <li>$MaPML_\tau-O$: 提案手法によって学習した距離函数を用いて，元のデータ空間で3近傍をとる</li>
</ul>

<p>データセットはMNIST, CIFAR-10, CIFAR-100およびImageNet</p>

<h3 id="mnist">MNIST</h3>
<ul>
  <li>latent examplesの数を変えながら性能比較．</li>
</ul>

<p><img width="400" alt="スクリーンショット 2018-08-13 15.27.59.png (74.9 kB)" src="https://img.esa.io/uploads/production/attachments/9763/2018/08/13/40745/889b7bc5-50ed-4f53-9df8-d4550d021a1b.png" /></p>

<ul>
  <li>学習時間の比較</li>
</ul>

<p><img width="400" alt="スクリーンショット 2018-08-13 15.28.04.png (63.2 kB)" src="https://img.esa.io/uploads/production/attachments/9763/2018/08/13/40745/ea1c620c-7253-42a8-9770-32a231462d40.png" /></p>

<h1 id="考察">考察</h1>
<p>MNISTのようなトイデータよりも，CIFARやImageNetのようなnatural objectsのデータセットの方が良好な結果が得られている．
画像データについてナイーブな距離指標を当てても基本的にうまくいかないのでmetric learningは重要になってきそう．</p>


  </article>
</div>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <br><br>
        <a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="vertical-normal" data-hatena-bookmark-lang="ja" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
        <a href="https://twitter.com/share" class="twitter-share-button" data-via="machinery81">Tweet</a><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
      </div>
    </div>
    
    <footer class="footer">
  <div id="gotop">^</div>
  <br>
	@2015 Pithy Theme by Pawpaw.
</footer>

    
  </body>

</html>
