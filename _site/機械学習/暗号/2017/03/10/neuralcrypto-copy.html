<!DOCTYPE html>
<html>    
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width initial-scale=1">

  <title>ニューラルネットワークと暗号化及び機密性の確保</title>
  <meta name="description" content="アリスはボブにセキュアにメッセージを送りたいと考えている。また、第三の攻撃者であるイブはそのメッセージを盗聴したいと考えている。ここで、セキュリティ属性は機密性であり、攻撃者は通信を傍受できる受動的攻撃者であるが、セッションを開始したり、メッセージを改ざんしたりといった能動的攻撃は制限されているものとする。">
  <meta name=”twitter:card” content=”summary”>
  <meta name="twitter:title" content="ニューラルネットワークと暗号化及び機密性の確保">
  <meta name="twitter:description" content="nocohub">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/%E6%9A%97%E5%8F%B7/2017/03/10/neuralcrypto-copy.html">
  <link rel="alternate" type="application/atom+xml" title="nocohub" href="http://localhost:4000/feed.xml" />
  <script src="/scripts/jquery-1.11.2.min.js"></script>
  <script src="/scripts/pithy.js"></script>
</head>


  <body>
    <header class="header">
	<div class="header-container">
		<div class="nav">
			
				<li>
					<a href="/index">home</a>
				</li>			
			
			
				<li>
					<a href="/archive">archive</a>
				</li>			
			
			
				<li>
					<a href="/category">category</a>
				</li>			
			
			
				<li>
					<a href="/about">about</a>
				</li>			
			
		</div>
		<div class="description">  </div>		
		<ul class="social-links">
			<li>
				<a href="https://github.com/nocotan" title="Github">
					<img width="19px" height="19px" src="/images/github.png"/>
				</a>
			</li>
			<li>
				<a href="/feed.xml" title="RSS">
					<img width="19px" height="19px" src="/images/rss.png"/>
				</a>
			</li>
			<li>
				<a href="https://twitter.com/machinery81" title="Twitter">
					<img width="19px" height="19px" src="/images/twitter.png"/>
				</a>
			</li>
		</ul>
	</div>
</header>

    <br>
    <div class="page-content">
      <div class="wrapper">
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$']]}
    });
</script>
<div class="post">
  <br>
  <header class="post-header">
    <h1 class="post-title">ニューラルネットワークと暗号化及び機密性の確保</h1>
    <p class="post-meta">Mar 10, 2017</p>
  </header>

  <article class="post-content">
    <p>アリスはボブにセキュアにメッセージを送りたいと考えている。
また、第三の攻撃者であるイブはそのメッセージを盗聴したいと考えている。
ここで、セキュリティ属性は機密性であり、攻撃者は通信を傍受できる受動的攻撃者で
あるが、セッションを開始したり、メッセージを改ざんしたりといった能動的攻撃は制
限されているものとする。</p>

<h2 id="システム構成">システム構成</h2>
<p>アリスはボブに平文Pを送信したいものとする。ここでアリスはPを暗号文Cに暗号化し、
ボブに送る。ボブはCを正確に複合し、複合文P<sub>Bob</sub>を得たい。同時に、イブ
も暗号文Cを傍受し複合文P<sub>Eve</sub>を得ようと試みる。</p>

<p><img src="https://raw.githubusercontent.com/nocotan/nocotan.github.io/master/images/neuralcrypto.png" alt="画像" /></p>

<h2 id="登場人物をニューラルネットワークとして考える">登場人物をニューラルネットワークとして考える</h2>
<p>ここで、アリス、ボブ、イブの各登場人物をニューラルネットワークAlice,Bob,Eveとす
る。</p>

<ul>
  <li>Aliceは平文Pと秘密鍵Kを入力として受け取り暗号文Cを出力する</li>
  <li>Bobは暗号文Cと秘密鍵Kを入力として受け取り複合文P<sub>Bob</sub>を出力する</li>
  <li>Eveは暗号文Cを入力として受け取り複合文P<sub>Eve</sub>を出力する</li>
</ul>

<p>ここで注目するのが、暗号化の際に、特定の暗号アルゴリズムを指定して用いている訳
ではないという点である。既知のアルゴリズムを用いていないため、攻撃者もニューラ
ルネットワークを構築して複合化を試みる。また、攻撃者のニューラルネットワークEve
は第三者的立場としての最善のモデルを使用することを仮定する。秘密鍵Kを平文Pごと
に新しく作成するワンタイムパッド方式であり、KとPの長さが同じであることは強制さ
れない。</p>

<h2 id="定義">定義</h2>

<p>それぞれの目的は以下のようになる。</p>

<ul>
  <li>アリスはボブに、第三者に知られないようにメッセージを送りたい</li>
  <li>ボブとイブは平文との誤りがより少なくなるように複合文を生成したい</li>
</ul>

<p>それぞれのモデルのパラメータをθ<sub>A</sub>,θ<sub>B</sub>,θ<sub>E</sub>とすると
、</p>

<ul>
  <li>Aliceの出力: A(θ<sub>A</sub>,P,K) = C</li>
  <li>Bobの出力: B(θ<sub>B</sub>,C,K)</li>
  <li>Eveの出力: E(θ<sub>E</sub>,P)</li>
</ul>

<p>また、距離関数d(P,P’) = Σ<sub>i=1,N</sub>|P<sub>i</sub> - P’&lt;/sub&gt;i&lt;/sub&gt;|とす
る。(Nは平文の長さ)。Eveについての誤差関数L<sub>E</sub>は、<br />
<strong>L<sub>E</sub>(θ<sub>A</sub>,θ<sub>E</sub>,P,K) = d(P,E(θ<sub>E</sub>,A(θ
<sub>A</sub>,P,K)))</strong></p>

<p>Eveの目的関数O<sub>E</sub>は、<br />
<strong>O<sub>E</sub>(θ<sub>A</sub>) = argmin<sub>θE</sub>(L<sub>E</sub>(θ
<sub>A</sub>,θ<sub>E</sub>))</strong></p>

<p>同様に、Bobには例ごとの複合化誤差を定義し、平文と秘密鍵の分布に拡張する。<br />
<strong>L<sub>B</sub>(θ<sub>A</sub>,θ<sub>B</sub>,P,K) = d(P,B(θ<sub>B</sub>,A(θ
<sub>A</sub>,P,K),K))</strong><br />
<strong>L<sub>B</sub>(θ<sub>A</sub>,θ<sub>B</sub>) = iE<sub>P,K</sub>(d(P,B(θ
<sub>B</sub>,A(θ<sub>A</sub>,P,K),K)))</strong></p>

<p>AliceとBobの誤差関数L<sub>AB</sub>は、<br />
<strong>L<sub>AB</sub>(θ<sub>A</sub>,θ<sub>B</sub>) = L<sub>B</sub>(θ<sub>A</sub>,θ<sub>B</sub>) - L<sub>E</sub>(θ<sub>A</sub>,O<sub>E</sub>(θ<sub>A</sub>))</strong></p>

<p>最後に、AliceとBobの目的関数O<sub>A</sub>,O<sub>B</sub>は、<br />
<strong>(O<sub>A</sub>,O<sub>B</sub>) = argmin<sub>(θA,θB)</sub>(L<sub>AB</sub>(θ<sub>A</sub>,θ<sub>B</sub>))</strong></p>

<h2 id="学習及びアーキテクチャ">学習及びアーキテクチャ</h2>
<p>学習はSGDに基づく。また、それぞれのモデルは個別に学習を行う。</p>
<ul>
  <li>全結合層を最初の層にもつ</li>
  <li>全結合層の後に畳み込み層のシーケンスが続き、最終的に平文または暗号文に適した
サイズの出力を生成する</li>
</ul>

<p>Python(TensorFlow)による実装(一部抜粋)</p>
<div class="highlighter-rouge"><pre class="highlight"><code>def build_model(self):
        # Weights for fully connected layers
        self.w_alice = init_weights("alice_w", [2 * self.N, 2 * self.N])
        self.w_bob = init_weights("bob_w", [2 * self.N, 2 * self.N])
        self.w_eve1 = init_weights("eve_w1", [self.N, 2 * self.N])
        self.w_eve2 = init_weights("eve_w2", [2 * self.N, 2 * self.N])

        # Placeholder variables for Message and Key
        self.msg = tf.placeholder("float", [None, self.msg_len])
        self.key = tf.placeholder("float", [None, self.key_len])

        # Alice's network
        # FC layer -&gt; Conv Layer (4 1-D convolutions)
        self.alice_input = tf.concat(concat_dim=1, values=[self.msg, self.key])
        self.alice_hidden = tf.nn.sigmoid(tf.matmul(self.alice_input, self.w_alice))
        self.alice_hidden = tf.expand_dims(self.alice_hidden, 2)
        self.alice_output = tf.squeeze(conv_layer(self.alice_hidden, "alice"))

        # Bob's network
        # FC layer -&gt; Conv Layer (4 1-D convolutions)
        self.bob_input = tf.concat(concat_dim=1, values=[self.alice_output, self.key])
        self.bob_hidden = tf.nn.sigmoid(tf.matmul(self.bob_input, self.w_bob))
        self.bob_hidden = tf.expand_dims(self.bob_hidden, 2)
        self.bob_output = tf.squeeze(conv_layer(self.bob_hidden, "bob"))

        # Eve's network
        # FC layer -&gt; FC layer -&gt; Conv Layer (4 1-D convolutions)
        self.eve_input = self.alice_output
        self.eve_hidden1 = tf.nn.sigmoid(tf.matmul(self.eve_input, self.w_eve1))
        self.eve_hidden2 = tf.nn.sigmoid(tf.matmul(self.eve_hidden1, self.w_eve2))
        self.eve_hidden2 = tf.expand_dims(self.eve_hidden2, 2)
        self.eve_output = tf.squeeze(conv_layer(self.eve_hidden2, "eve"))

 def train(self):
        # Loss Functions
        self.decrypt_err_eve = tf.reduce_mean(tf.abs(self.msg - self.eve_output))
        self.decrypt_err_bob = tf.reduce_mean(tf.abs(self.msg - self.bob_output))
        self.loss_bob = self.decrypt_err_bob + (1. - self.decrypt_err_eve) ** 2.

        # Get training variables corresponding to each network
        self.t_vars = tf.trainable_variables()
        self.alice_or_bob_vars = [var for var in self.t_vars if 'alice_' in var.name or 'bob_' in var.name]
        self.eve_vars = [var for var in self.t_vars if 'eve_' in var.name]

        # Build the optimizers
        self.bob_optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(
            self.loss_bob, var_list=self.alice_or_bob_vars)
        self.eve_optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(
            self.decrypt_err_eve, var_list=self.eve_vars)

        self.bob_errors, self.eve_errors = [], []

        # Begin Training
        tf.initialize_all_variables().run()
        for i in range(self.epochs):
            iterations = 2000

            print 'Training Alice and Bob, Epoch:', i + 1
            bob_loss, _ = self._train('bob', iterations)
            self.bob_errors.append(bob_loss)

            print 'Training Eve, Epoch:', i + 1
            _, eve_loss = self._train('eve', iterations)
            self.eve_errors.append(eve_loss)

        self.plot_errors()
</code></pre>
</div>

<p><a href="https://arxiv.org/pdf/1610.06918.pdf">Google Brainによる論文</a></p>

  </article>
</div>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <br><br>
        <a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="vertical-normal" data-hatena-bookmark-lang="ja" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
        <a href="https://twitter.com/share" class="twitter-share-button" data-via="machinery81">Tweet</a><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
      </div>
    </div>
    
    <footer class="footer">
  <div id="gotop">^</div>
  <br>
	@2015 Pithy Theme by Pawpaw.
</footer>

    
  </body>

</html>
