---
layout: post
title:  "node2vec"
date:   2017-07-01 01:00:00
categories: 機械学習
---

KDD2016に採択された論文, [node2vec: Scalable Feature Learning for Networks](https://cs.stanford.edu/people/jure/pubs/node2vec-kdd16.pdf)について.  
目標は, オブジェクト集合の特徴を学習すること.  
提案手法はあるタスク特有のものではなく, 任意のタスクに適用可能なものである.  
また, 有向, 無向, 重み付き, 重み無しのグラフに適用可能.

## グラフ上での特徴学習
グラフG = (V, E)が与えられる. ここで, Vはノード集合, Eはエッジ集合とする.
また, マッピング関数fを以下のように定義する:  

![eq1](/images/20170701/eq1.png)

直感的に, 何らかノードの類似性を保持したまま, ノードからd次元の特徴へのマッピングを見つけたいことがわかる.
単純なアイディアとして, 近くのノードが近くに存在するようにノードの埋め込みを学習する.
ノードu ∈ Vが与えられた時, 近傍サンプリングSから導かれるノードuの近傍をN<sub>S</sub>(u)と定義する. 
この近傍ノードN<sub>S</sub>(u)を予測することによって最適な重みを見つけたい(尤度最大化問題).
よって, 以下の目的関数を最適化することを目指す.
これはfによって与えられた特徴表現を条件とするノードuのネットワーク近傍N<sub>S</sub>を観測する対数確率を最大化する問題に帰結する.

![eq2](/images/20170701/eq2.png)

ここで, 最適化問題を扱いやすくするために, 二つの仮定を導入する.

* 条件付き独立である
* 特徴空間において対称である

これらの基本的な仮定に基づいて, Prは以下のように定義される.  

![eq3](/images/20170701/eq3.png)

以上より, 式2は以下のように単純化できる:

![eq4](/images/20170701/eq4.png)

ノード分割関数Z<sub>u</sub> = Σ(f(u)・f(v))は大規模ネットワーク上で計算でき, ネガティブサンプリングを用いてこれを計算できる.
式5により, 確率的勾配降下法(SGD: Stochastic Gradient Descent)を用いてf(u)を最適化する.

## 近傍ノードの決定
与えられたノードの近傍ノードを決定するために, 幅優先探索(BFS)と深さ優先探索(DFS)という2つの古典的な探索手法がある.
近傍3ノードを探索する際のDFSとBFSの動作を図1に示す.

<img src="/images/20170701/fig1.png" width="450px">

特に, グラフ上でのノード予測タスクは二種類の類似度に基づく(構造的等価性と共起表現的等価性).
共起表現的等価性の下では, 相互に接続されており, 同様のクラスタまたはコミュニティに属するノードは密に埋め込まれるべきである.
対照的に, 構造上の等価性仮説の下ではグラフにおいて類似の構造的役割を有するノードが密に埋め込まれるべきである.  
重要なことに, 共起表現とは異なり, 構造上の同等性は接続性を重要視していない.
これは, ノードはグラフ上では遠く離れていても, 同じ構造的役割を持っていることがあるためである.
実世界において, これらの等価概念は排他的ではない.
グラフは, いくつかのノードが共起表現的等価性を示し, 他のノードが構造的等価性を示す.
BFSとDFSのどちらを採用するかは構造的等価性と共起表現的等価性のどちらを優先するかで決まる.

<img src="/images/20170701/fig2.png" width="450px">

## node2vec
上記を元にBFSとDFSを円滑に補間するための柔軟な近傍サンプリングを設計する.

### ランダムウォーク
ソースノードuが与えられると, 固定長lのランダムウォークを行う. c<sub>i</sub>を歩行中のi番目のノードとし, c<sub>0</sub> = uでランダムウォークを開始する.
ノードc<sub>i</sub>は以下の分布によって導かれる.

![eq5](/images/20170701/eq5.png)

ここで, π<sub>vx</sub>はノードvとノードxとの間の正規化されていない遷移確率であり, Zは正規化定数である.

### 探索バイアスα
パラメータpとqから導かれる二次ランダムウォークを定義する.
エッジ(t, v)を通過してノードvに存在するランダムウォークを考える.
ウォークは次のステップを決定する必要があるため, vから導かれるエッジ(v, x)上の遷移確率π<sub>vx</sub> = α<sub>pq</sub>(t, x)・w<sub>vx</sub>とすると, 

![eq6](/images/20170701/eq6.png)

d<sub>tx</sub>はノードtとノードx間の最短経路距離を表す.
d<sub>tx</sub>は{0, 1, 2}のいずれかでなくてはならない.
直感的にパラメータp及びqはランダムウォークがどのくらい早く探索し, 開始ノードuの近傍を離れるかを制御する.
パラメータpは歩行中のノードを再訪する可能性を制御する.
このパラメータを高い値に設定することで, 次の2ステップですでに訪れたノードをサンプリングする可能性が低くなる.
この設定は適度な探索を促し, サンプリングに置ける2ホップ冗長性を回避する.
一方pの値が低い場合, ウォークは開始ノードから離れにくくなる.
パラメータpは探索が「内向き」及び「外向き」のノードを区別することを可能にする.
q &gt; 1の場合, ランダムウォークはノードtに近いノードに向かってバイアスされる.
対照的に, q &lt; 1の場合, 歩行はノードtから遠いノードをより多く訪問する傾向がある.

<img src="/images/20170701/fig3.png" width="500px">

### ランダムウォークのメリット
純粋なBFS/DFSアプローチに比べてランダムウォークにはいくつかの利点がある.
ランダムウォークは空間的及び時間的要件の両方において計算的に効率的である.
グラフ内の各ノードの直近の近傍を格納する空間的計算量はO(|E|)である.
二次ランダムウォークでは, 全てのノードの隣接ノード間に相互接続を格納すると, 空間的計算量はO(a<sup>2</sup>|V|)となる.
ここで, aはグラフの平均次数であり, 実世界のネットワークでは小さくなる.
古典的探索手法よりもランダムウォークが優れているもう一つの点は, 時間的計算量についてである.
特に, サンプル生成プロセスにグラフ接続性を課すことにより, ランダムウォークは異なるソース間でサンプルを再利用することができる.

<img src="/images/20170701/code.png" width="450px">
